{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import BertModel, BertTokenizerFast\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sparsemax import Sparsemax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForDiseasePrediction(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=49, bias=True)\n",
       "  (sparsemax): Sparsemax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the BERT-CF on Disease Prediction Model\n",
    "class BertForDiseasePrediction(nn.Module):\n",
    "    def __init__(self, bert_model, num_diseases):\n",
    "        super(BertForDiseasePrediction, self).__init__()\n",
    "        self.bert = bert_model  # Use the pre-trained BERT model\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = False  # Freeze BERT parameters\n",
    "        \n",
    "        # Disease classification head\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_diseases)\n",
    "\n",
    "        # Sparsemax Activation function\n",
    "        self.sparsemax = Sparsemax(dim=1)\n",
    "\n",
    "        # Initialize weights\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        \"\"\"\n",
    "        Initialize the weights of the classification layer.\n",
    "        \"\"\"\n",
    "        nn.init.xavier_uniform_(self.classifier.weight)\n",
    "        if self.classifier.bias is not None:\n",
    "            nn.init.zeros_(self.classifier.bias)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask=None, token_type_ids=None, labels=None):\n",
    "        \n",
    "        outputs = self.bert(input_ids=input_ids, \n",
    "                            attention_mask=attention_mask, \n",
    "                            token_type_ids=token_type_ids,\n",
    "                            return_dict=True)\n",
    "        \n",
    "        # Extract the [CLS] token's embedding\n",
    "        cls_embedding = outputs.last_hidden_state[:, 0, :]\n",
    "        \n",
    "        # Compute logits\n",
    "        logits = self.classifier(cls_embedding)\n",
    "        \n",
    "        # Apply Sparsemax activation\n",
    "        probs = self.sparsemax(logits)\n",
    "        \n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.MSELoss()\n",
    "            loss = loss_fct(probs, labels)\n",
    "        \n",
    "        return {'loss': loss, 'probs': probs}\n",
    "\n",
    "    \n",
    "class DiseasePredictionDataset(Dataset):\n",
    "    def __init__(self, encodings, disease_labels):\n",
    "        self.encodings = encodings\n",
    "        self.disease_labels = disease_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.disease_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.disease_labels[idx], dtype=torch.float32)\n",
    "        return item\n",
    "\n",
    "    \n",
    "# Load the pre-trained BERT model\n",
    "pretrained_model = BertModel.from_pretrained('../models/pretrained_model')\n",
    "\n",
    "# Initialize your disease prediction model\n",
    "num_diseases = 49  # Adjust this if your number of diseases is different\n",
    "model_disease = BertForDiseasePrediction(pretrained_model, num_diseases)\n",
    "\n",
    "from safetensors.torch import load_file\n",
    "\n",
    "# Load the state dictionary from the safetensors file\n",
    "state_dict = load_file('../models/disease_prediction_model/model.safetensors')\n",
    "\n",
    "# Load the state dictionary into your model\n",
    "model_disease.load_state_dict(state_dict)\n",
    "\n",
    "# Move the model to the appropriate device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_disease.to(device)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model_disease.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your data\n",
    "data = pd.read_csv('../../data/input.csv')\n",
    "\n",
    "# Select the subset from index 1000 to 2000\n",
    "data_test = data[1000:2000].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizerFast\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenize the input texts\n",
    "tokenized_inputs_test = tokenizer(\n",
    "    data_test['X'].tolist(),\n",
    "    truncation=True,\n",
    "    padding='max_length',\n",
    "    max_length=512,\n",
    "    return_tensors='pt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def parse_y_entry(y_str):\n",
    "    try:\n",
    "        # Remove square brackets and newlines\n",
    "        y_str_clean = y_str.strip('[]').replace('\\n', ' ')\n",
    "        # Split the string by whitespace to get individual numbers\n",
    "        y_list = y_str_clean.split()\n",
    "        # Convert to floats\n",
    "        y_floats = [float(num) for num in y_list]\n",
    "        # Convert to NumPy array\n",
    "        y_array = np.array(y_floats, dtype=np.float32)\n",
    "        return y_array\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing Y entry: {y_str}\")\n",
    "        raise e\n",
    "\n",
    "# Apply the parsing function to get labels\n",
    "disease_labels_test = data_test['Y'].apply(parse_y_entry).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset\n",
    "dataset_test = DiseasePredictionDataset(tokenized_inputs_test, disease_labels_test)\n",
    "\n",
    "# Create a DataLoader\n",
    "test_loader = DataLoader(dataset_test, batch_size=8, shuffle=False)  # Adjust batch_size as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_outputs = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        token_type_ids = batch['token_type_ids'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model_disease(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "\n",
    "        probs = outputs['probs']  # Raw logits before sigmoid\n",
    "\n",
    "        all_outputs.append(probs.cpu())\n",
    "        all_labels.append(labels.cpu())\n",
    "\n",
    "# Concatenate all outputs and labels\n",
    "all_outputs = torch.cat(all_outputs, dim=0)\n",
    "all_labels = torch.cat(all_labels, dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.0000, 0.0541,  ..., 0.0000, 0.1244, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.5037, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.2350, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.3289, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.4255, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "# Apply sigmoid to convert logits to probabilities\n",
    "# all_probs = torch.sigmoid(all_outputs)\n",
    "\n",
    "print(all_outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0395, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.5443, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "#print(all_probs)\n",
    "print(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the differences between predicted probabilities and true labels\n",
    "differences = all_outputs - all_labels\n",
    "\n",
    "# Compute the absolute differences\n",
    "abs_differences = differences.abs()\n",
    "\n",
    "# Average the absolute differences for each column (disease)\n",
    "mean_abs_differences = abs_differences.mean(dim=0)\n",
    "\n",
    "# Convert to NumPy array for easier handling\n",
    "mean_abs_differences = mean_abs_differences.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disease 0: Mean absolute difference: 0.0059\n",
      "Disease 1: Mean absolute difference: 0.0363\n",
      "Disease 2: Mean absolute difference: 0.0190\n",
      "Disease 3: Mean absolute difference: 0.0196\n",
      "Disease 4: Mean absolute difference: 0.0170\n",
      "Disease 5: Mean absolute difference: 0.0062\n",
      "Disease 6: Mean absolute difference: 0.0201\n",
      "Disease 7: Mean absolute difference: 0.1163\n",
      "Disease 8: Mean absolute difference: 0.0441\n",
      "Disease 9: Mean absolute difference: 0.0325\n",
      "Disease 10: Mean absolute difference: 0.0213\n",
      "Disease 11: Mean absolute difference: 0.0097\n",
      "Disease 12: Mean absolute difference: 0.0001\n",
      "Disease 13: Mean absolute difference: 0.0663\n",
      "Disease 14: Mean absolute difference: 0.0199\n",
      "Disease 15: Mean absolute difference: 0.0434\n",
      "Disease 16: Mean absolute difference: 0.0089\n",
      "Disease 17: Mean absolute difference: 0.0313\n",
      "Disease 18: Mean absolute difference: 0.0258\n",
      "Disease 19: Mean absolute difference: 0.0027\n",
      "Disease 20: Mean absolute difference: 0.0079\n",
      "Disease 21: Mean absolute difference: 0.0315\n",
      "Disease 22: Mean absolute difference: 0.0318\n",
      "Disease 23: Mean absolute difference: 0.0324\n",
      "Disease 24: Mean absolute difference: 0.0203\n",
      "Disease 25: Mean absolute difference: 0.0131\n",
      "Disease 26: Mean absolute difference: 0.0158\n",
      "Disease 27: Mean absolute difference: 0.0300\n",
      "Disease 28: Mean absolute difference: 0.0215\n",
      "Disease 29: Mean absolute difference: 0.0230\n",
      "Disease 30: Mean absolute difference: 0.1413\n",
      "Disease 31: Mean absolute difference: 0.0830\n",
      "Disease 32: Mean absolute difference: 0.0175\n",
      "Disease 33: Mean absolute difference: 0.0133\n",
      "Disease 34: Mean absolute difference: 0.1625\n",
      "Disease 35: Mean absolute difference: 0.0479\n",
      "Disease 36: Mean absolute difference: 0.0345\n",
      "Disease 37: Mean absolute difference: 0.0100\n",
      "Disease 38: Mean absolute difference: 0.0084\n",
      "Disease 39: Mean absolute difference: 0.0169\n",
      "Disease 40: Mean absolute difference: 0.0272\n",
      "Disease 41: Mean absolute difference: 0.0086\n",
      "Disease 42: Mean absolute difference: 0.0042\n",
      "Disease 43: Mean absolute difference: 0.0159\n",
      "Disease 44: Mean absolute difference: 0.0222\n",
      "Disease 45: Mean absolute difference: 0.2172\n",
      "Disease 46: Mean absolute difference: 0.0292\n",
      "Disease 47: Mean absolute difference: 0.1551\n",
      "Disease 48: Mean absolute difference: 0.0063\n"
     ]
    }
   ],
   "source": [
    "# Print the average absolute differences for each disease\n",
    "for i, mean_diff in enumerate(mean_abs_differences):\n",
    "    print(f'Disease {i}: Mean absolute difference: {mean_diff:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
