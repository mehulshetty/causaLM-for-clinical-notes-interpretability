{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import BertModel, BertTokenizerFast\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sparsemax import Sparsemax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the BERT-CF on Disease Prediction Model\n",
    "class BertForDiseasePrediction(nn.Module):\n",
    "    def __init__(self, bert_model, num_diseases):\n",
    "        super(BertForDiseasePrediction, self).__init__()\n",
    "        self.bert = bert_model  # Use the pre-trained BERT model\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = False  # Freeze BERT parameters\n",
    "        \n",
    "        # Disease classification head\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_diseases)\n",
    "\n",
    "        # Sparsemax Activation function\n",
    "        self.sparsemax = Sparsemax(dim=1)\n",
    "\n",
    "        # Initialize weights\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        \"\"\"\n",
    "        Initialize the weights of the classification layer.\n",
    "        \"\"\"\n",
    "        nn.init.xavier_uniform_(self.classifier.weight)\n",
    "        if self.classifier.bias is not None:\n",
    "            nn.init.zeros_(self.classifier.bias)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask=None, token_type_ids=None, labels=None):\n",
    "        \n",
    "        outputs = self.bert(input_ids=input_ids, \n",
    "                            attention_mask=attention_mask, \n",
    "                            token_type_ids=token_type_ids,\n",
    "                            return_dict=True)\n",
    "        \n",
    "        # Extract the [CLS] token's embedding\n",
    "        cls_embedding = outputs.last_hidden_state[:, 0, :]\n",
    "        \n",
    "        # Compute logits\n",
    "        logits = self.classifier(cls_embedding)\n",
    "        \n",
    "        # Apply Sparsemax activation\n",
    "        probs = self.sparsemax(logits)\n",
    "        \n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.MSELoss()\n",
    "            loss = loss_fct(probs, labels)\n",
    "        \n",
    "        return {'loss': loss, 'probs': probs}\n",
    "\n",
    "    \n",
    "class DiseasePredictionDataset(Dataset):\n",
    "    def __init__(self, encodings, disease_labels, concept_indicators):\n",
    "        self.encodings = encodings\n",
    "        self.disease_labels = disease_labels\n",
    "        self.concept_indicators = concept_indicators\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.disease_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.disease_labels[idx], dtype=torch.float32)\n",
    "        # Add concept_indicator to the batch item\n",
    "        item['concept_indicator'] = torch.tensor(self.concept_indicators[idx], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "    \n",
    "# Load the pre-trained BERT model\n",
    "pretrained_model = BertModel.from_pretrained('../models/pretrained_model')\n",
    "\n",
    "# Initialize your disease prediction model\n",
    "num_diseases = 49  # Adjust this if your number of diseases is different\n",
    "model_disease = BertForDiseasePrediction(pretrained_model, num_diseases)\n",
    "\n",
    "from safetensors.torch import load_file\n",
    "\n",
    "# Load the state dictionary from the safetensors file\n",
    "state_dict = load_file('../models/disease_prediction_model/model.safetensors')\n",
    "\n",
    "# Load the state dictionary into your model\n",
    "model_disease.load_state_dict(state_dict)\n",
    "\n",
    "# Move the model to the appropriate device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_disease.to(device)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model_disease.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your data\n",
    "data = pd.read_csv('../../data/input.csv')\n",
    "\n",
    "# Select the subset from index 1000 to 2000\n",
    "data_test = data[100000:115000].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the concept_indicator column\n",
    "# If 'chest' appears in the text, concept_indicator = 1, else 0\n",
    "concept_indicator_array = np.where(data_test['X'].str.lower().str.contains('chest'), 1, 0)\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenize the input texts\n",
    "tokenized_inputs_test = tokenizer(\n",
    "    data_test['X'].tolist(),\n",
    "    truncation=True,\n",
    "    padding='max_length',\n",
    "    max_length=512,\n",
    "    return_tensors='pt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_y_entry(y_str):\n",
    "    try:\n",
    "        # Clean and parse labels\n",
    "        y_str_clean = y_str.strip('[]').replace('\\n', ' ')\n",
    "        y_list = y_str_clean.split()\n",
    "        y_floats = [float(num) for num in y_list]\n",
    "        return np.array(y_floats, dtype=np.float32)\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing Y entry: {y_str}\")\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_labels_test = data_test['Y'].apply(parse_y_entry).tolist()\n",
    "\n",
    "# Create the dataset with concept_indicator\n",
    "dataset_test = DiseasePredictionDataset(tokenized_inputs_test, disease_labels_test, concept_indicator_array)\n",
    "\n",
    "# Create DataLoader\n",
    "test_loader = DataLoader(dataset_test, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_outputs = []\n",
    "all_labels = []\n",
    "all_concept_presence = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        token_type_ids = batch['token_type_ids'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        concept_indicator = batch['concept_indicator']  # remains on CPU\n",
    "\n",
    "        outputs = model_disease(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "\n",
    "        probs = outputs['probs']\n",
    "\n",
    "        all_outputs.append(probs.cpu())\n",
    "        all_labels.append(labels.cpu())\n",
    "        all_concept_presence.append(concept_indicator.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_outputs = torch.cat(all_outputs, dim=0)\n",
    "all_concept_presence = torch.cat(all_concept_presence, dim=0)\n",
    "\n",
    "concept_present_indices = (all_concept_presence == 1)\n",
    "concept_absent_indices = (all_concept_presence == 0)\n",
    "\n",
    "probs_concept_present = all_outputs[concept_present_indices]\n",
    "probs_concept_absent = all_outputs[concept_absent_indices]\n",
    "\n",
    "mean_present = probs_concept_present.mean(dim=0)\n",
    "mean_absent = probs_concept_absent.mean(dim=0)\n",
    "\n",
    "conexp = mean_present - mean_absent\n",
    "print(\"CONEXP:\", conexp.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
